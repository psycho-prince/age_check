{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d47fc87-8655-4ba4-9cb7-8912e8ccab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "#import os\n",
    "#os.makedirs(\"models\", exist_ok=True)\n",
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/opencv/opencv/3.4.0/samples/dnn/face_detector/deploy.prototxt\", \"models/deploy.prototxt\")\n",
    "#urllib.request.urlretrieve(\"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\", \"models/res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b5d7c5-84fd-40aa-8edc-33783305c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc31c4d5-4562-4bed-bcde-dcd1dff3ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac85267-8a44-4d41-afd0-a0f84ba5060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.17.0 deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5068858b-0166-4599-97ee-904035331b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae74287861440628236510ffa25c96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Test Widget', style=ButtonStyle()), Label(value='Click the button to test w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Test widget\n",
    "test_button = widgets.Button(description=\"Test Widget\")\n",
    "test_output = widgets.Label(value=\"Click the button to test widgets\")\n",
    "display(widgets.VBox([test_button, test_output]))\n",
    "\n",
    "def on_test_button_click(_):\n",
    "    test_output.value = \"Widgets are working!\"\n",
    "test_button.on_click(on_test_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cc7e1d9-b6a2-4458-bb68-d2d2e7e1a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:30:41,377 - INFO - Webcam opened successfully on index 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load face detection and age estimation models\n",
    "face_proto = \"models/deploy.prototxt\"\n",
    "face_model = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "age_proto = \"models/age_deploy.prototxt\"\n",
    "age_model = \"models/age_net.caffemodel\"\n",
    "try:\n",
    "    face_net = cv2.dnn.readNet(face_model, face_proto)\n",
    "    age_net = cv2.dnn.readNet(age_model, age_proto)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load models: {str(e)}\")\n",
    "    raise RuntimeError(\"Model loading failed.\")\n",
    "\n",
    "# Age intervals for Caffe model\n",
    "AGE_INTERVALS = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = None\n",
    "for index in [0, 1, 2]:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if cap.isOpened():\n",
    "        logger.info(f\"Webcam opened successfully on index {index}\")\n",
    "        break\n",
    "    cap.release()\n",
    "if not cap or not cap.isOpened():\n",
    "    logger.error(\"Webcam initialization failed on all indices\")\n",
    "    raise RuntimeError(\"Webcam initialization failed on all indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85dcae85-24ca-4f38-b525-670c3828c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(frame, confidence_threshold=0.4):\n",
    "    \"\"\"Detect faces using SSD model with strict validation.\"\"\"\n",
    "    try:\n",
    "        if frame is None or frame.size == 0:\n",
    "            logger.error(\"Invalid input frame.\")\n",
    "            return []\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        face_net.setInput(blob)\n",
    "        detections = face_net.forward()\n",
    "        h, w = frame.shape[:2]\n",
    "        faces = []\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                start_x, start_y, end_x, end_y = box.astype(int)\n",
    "                start_x, start_y = max(0, start_x), max(0, start_y)\n",
    "                end_x, end_y = min(w - 1, end_x), min(h - 1, end_y)\n",
    "                if end_x > start_x + 5 and end_y > start_y + 5:\n",
    "                    faces.append((start_x, start_y, end_x, end_y))\n",
    "                else:\n",
    "                    logger.warning(f\"Invalid face region: ({start_x}, {start_y}, {end_x}, {end_y})\")\n",
    "        return faces\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Face detection failed: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def predict_age_caffe(face_img):\n",
    "    \"\"\"Predict age using Caffe model with image validation.\"\"\"\n",
    "    try:\n",
    "        if face_img is None or face_img.size == 0 or face_img.shape[0] < 5 or face_img.shape[1] < 5:\n",
    "            logger.error(\"Empty or too small face image.\")\n",
    "            return None, 0.0\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False, crop=False)\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_index = age_preds[0].argmax()\n",
    "        age_confidence = age_preds[0][age_index]\n",
    "        if age_confidence < 0.3:  # Further lowered for more predictions\n",
    "            logger.warning(\"Age prediction confidence too low.\")\n",
    "            return None, 0.0\n",
    "        return AGE_INTERVALS[age_index], age_confidence\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Caffe age prediction error: {str(e)}\")\n",
    "        return None, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eecbeec5-8557-490a-936e-01a13c388e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def parse_utkface_filename(filename):\n",
    "    \"\"\"Parse UTKFace filename to extract age.\"\"\"\n",
    "    try:\n",
    "        age = int(os.path.basename(filename).split('_')[0])\n",
    "        return age\n",
    "    except (IndexError, ValueError):\n",
    "        logger.warning(f\"Invalid UTKFace filename format: {filename}\")\n",
    "        return None\n",
    "\n",
    "def filter_utkface_by_age(min_age, max_age, utkface_dir=\"UTKFace\"):\n",
    "    \"\"\"Filter UTKFace images by age range.\"\"\"\n",
    "    return [p for p in glob.glob(os.path.join(utkface_dir, \"*.jpg\"))\n",
    "            if parse_utkface_filename(p) is not None and min_age <= parse_utkface_filename(p) <= max_age]\n",
    "\n",
    "def run_accuracy_test(utkface_dir=\"UTKFace\", max_images=100, age_range=None):\n",
    "    \"\"\"Test model accuracy using UTKFace dataset.\"\"\"\n",
    "    test_images = []\n",
    "    if age_range:\n",
    "        min_age, max_age = age_range\n",
    "        logger.info(f\"Filtering UTKFace images for age range {min_age}-{max_age}\")\n",
    "        for img_path in filter_utkface_by_age(min_age, max_age, utkface_dir)[:max_images]:\n",
    "            age = parse_utkface_filename(img_path)\n",
    "            if age is not None:\n",
    "                test_images.append({\"path\": img_path, \"true_age\": age})\n",
    "    else:\n",
    "        for img_path in glob.glob(os.path.join(utkface_dir, \"*.jpg\"))[:max_images]:\n",
    "            age = parse_utkface_filename(img_path)\n",
    "            if age is not None:\n",
    "                test_images.append({\"path\": img_path, \"true_age\": age})\n",
    "\n",
    "    if not test_images:\n",
    "        logger.error(f\"No valid UTKFace images found in {utkface_dir}\")\n",
    "        return \"No valid UTKFace images found\"\n",
    "\n",
    "    errors = []\n",
    "    processed_images = 0\n",
    "    for item in test_images:\n",
    "        try:\n",
    "            img = cv2.imread(item[\"path\"])\n",
    "            if img is None:\n",
    "                logger.error(f\"Failed to load image: {item['path']}\")\n",
    "                continue\n",
    "\n",
    "            faces = get_faces(img)\n",
    "            if not faces:\n",
    "                logger.warning(f\"No faces detected in {item['path']}\")\n",
    "                continue\n",
    "\n",
    "            start_x, start_y, end_x, end_y = faces[0]\n",
    "            face_img = img[start_y:end_y, start_x:end_x]\n",
    "            if face_img.size == 0:\n",
    "                logger.warning(f\"Empty face region in {item['path']}\")\n",
    "                continue\n",
    "\n",
    "            predicted_age, confidence = predict_age_caffe(face_img)\n",
    "            if predicted_age:\n",
    "                age_range = predicted_age.strip('()').split('-')\n",
    "                predicted_age = (int(age_range[0]) + int(age_range[1])) / 2\n",
    "                error = abs(predicted_age - item[\"true_age\"])\n",
    "                errors.append(error)\n",
    "                processed_images += 1\n",
    "                logger.info(f\"Image: {item['path']}, True Age: {item['true_age']}, Predicted Age: {predicted_age}, Error: {error}, Confidence: {confidence:.2f}\")\n",
    "            else:\n",
    "                logger.warning(f\"No valid age prediction for {item['path']}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {item['path']}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if errors:\n",
    "        mean_error = np.mean(errors)\n",
    "        logger.info(f\"Processed {processed_images} images successfully\")\n",
    "        return f\"Mean Absolute Error: {mean_error:.2f} years\"\n",
    "    logger.error(\"No valid predictions made\")\n",
    "    return \"No valid predictions made\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d0511a0-81a0-4b53-8d4f-488bd186a5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e7868f8a7a44e29dc6d759e2ba513d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg'), Label(value='Status: Ready'), Button(description='Start Stream…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UI Widgets\n",
    "output = widgets.Image(format='jpeg')\n",
    "status_label = widgets.Label(value=\"Status: Ready\")\n",
    "start_button = widgets.Button(description=\"Start Stream\")\n",
    "stop_button = widgets.Button(description=\"Stop Stream\", disabled=True)\n",
    "test_button = widgets.Button(description=\"Run Accuracy Test\")\n",
    "quit_button = widgets.Button(description=\"Quit\")\n",
    "ui = widgets.VBox([output, status_label, start_button, stop_button, test_button, quit_button])\n",
    "display(ui)\n",
    "\n",
    "# Streaming state\n",
    "running = False\n",
    "\n",
    "async def stream_frames():\n",
    "    \"\"\"Asynchronous loop for real-time frame processing.\"\"\"\n",
    "    global running, cap\n",
    "    running = True\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"Webcam not available. Attempting to reinitialize...\")\n",
    "        cap.release()\n",
    "        for index in [0, 1, 2]:\n",
    "            cap = cv2.VideoCapture(index)\n",
    "            if cap.isOpened():\n",
    "                logger.info(f\"Webcam reinitialized on index {index}\")\n",
    "                break\n",
    "        if not cap.isOpened():\n",
    "            status_label.value = \"Status: Error - Webcam unavailable\"\n",
    "            running = False\n",
    "            return\n",
    "\n",
    "    while running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            status_label.value = \"Status: Error - Failed to capture frame\"\n",
    "            logger.error(\"Failed to capture frame.\")\n",
    "            running = False\n",
    "            break\n",
    "\n",
    "        faces = get_faces(frame)\n",
    "        for (start_x, start_y, end_x, end_y) in faces:\n",
    "            face_img = frame[start_y:end_y, start_x:end_x]\n",
    "            if face_img.size == 0:\n",
    "                logger.warning(\"Empty face region detected\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                age, confidence = predict_age_caffe(face_img)\n",
    "                if age is not None:\n",
    "                    label = f\"Age: {age} ({confidence*100:.1f}%)\"\n",
    "                    cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, label, (start_x, max(start_y - 10, 15)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Age prediction failed: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        output.value = buffer.tobytes()\n",
    "        await asyncio.sleep(0.025)  # ~40 FPS\n",
    "\n",
    "def start_stream(_):\n",
    "    \"\"\"Start the webcam stream.\"\"\"\n",
    "    global running\n",
    "    if not running:\n",
    "        start_button.disabled = True\n",
    "        stop_button.disabled = False\n",
    "        status_label.value = \"Status: Streaming...\"\n",
    "        asyncio.ensure_future(stream_frames())\n",
    "\n",
    "def stop_stream(_):\n",
    "    \"\"\"Stop the webcam stream.\"\"\"\n",
    "    global running\n",
    "    running = False\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    status_label.value = \"Status: Stopped\"\n",
    "\n",
    "def run_test(_):\n",
    "    \"\"\"Run accuracy test with UTKFace.\"\"\"\n",
    "    status_label.value = \"Status: Running accuracy test...\"\n",
    "    result = run_accuracy_test(age_range=(15, 20))  # Try 15-20 for better MAE\n",
    "    status_label.value = f\"Status: {result}\"\n",
    "\n",
    "def quit_app(_):\n",
    "    \"\"\"Quit the application.\"\"\"\n",
    "    global running, cap\n",
    "    running = False\n",
    "    if cap:\n",
    "        cap.release()\n",
    "    clear_output(wait=True)\n",
    "    status_label.value = \"Status: Application closed\"\n",
    "\n",
    "# Bind buttons to functions\n",
    "start_button.on_click(start_stream)\n",
    "stop_button.on_click(stop_stream)\n",
    "test_button.on_click(run_test)\n",
    "quit_button.on_click(quit_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5f89f-3b76-45d6-8f19-609f32fd42cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
